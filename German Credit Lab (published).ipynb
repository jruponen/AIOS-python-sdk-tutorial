{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Watson OpenScale Lab: Validating a German Credit Risk Model for Fairness and Accuracy\n",
    "\n",
    "Documentation: https://console.bluemix.net/docs/services/ai-openscale/tutorial-adv.html#tutorial-advanced-  \n",
    "Source: https://github.com/emartensibm/german-credit  \n",
    "Version 2019-03-17 by Jukka Ruponen/IBM\n",
    "\n",
    "**The level of current credit risk modeling in financial sector**\n",
    "\n",
    "Traditional lenders are under pressure to expand their digital portfolio of financial services to a larger and more diverse audience, which requires a new approach to credit risk modeling. Their data science teams currently rely on standard modeling techniques - like decision trees and logistic regression - which work well for moderate datasets, and make recommendations that can be easily explained. This satisfies regulatory requirements that credit lending decisions must be transparent and explainable.\n",
    "\n",
    "**Possible futures of credit risk modeling**\n",
    "\n",
    "To provide credit access to a wider and riskier population, applicant credit histories must expand beyond traditional credit, like mortgages and car loans, to alternate credit sources like utility and mobile phone plan payment histories, plus education and job titles. These new data sources offer promise, but also introduce risk by increasing the likelihood of unexpected correlations which introduce bias based on an applicantâ€™s age, gender, or other personal traits.\n",
    "\n",
    "**Concerns & GDPR**\n",
    "\n",
    "The data science techniques most suited to these diverse datasets, such as gradient boosted trees and neural networks, can generate highly accurate risk models, but at a cost. Such \"black box\" models generate opaque predictions that must somehow become transparent, to ensure regulatory approval such as Article 22 of the General Data Protection Regulation (GDPR), or the federal Fair Credit Reporting Act (FCRA) managed by the Consumer Financial Protection Bureau.\n",
    "\n",
    "The credit risk model provided in this tutorial uses a training dataset that contains 20 attributes about each loan applicant. Two of those attributes - age and sex - can be tested for bias. For this tutorial, the focus will be on bias against sex and age.\n",
    "\n",
    "Watson OpenScale will monitor the deployed model's propensity for a favorable outcome (\"No Risk\") for one group (the Reference Group) over another (the Monitored Group). In this tutorial, the Monitored Group for sex is female, while the Monitored Group for age is 18 to 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Pre-requisities\n",
    "2. Required packages installation\n",
    "3. Configuring credentials and settings required to run this Notebook\n",
    "4. Load and explore data for model training\n",
    "5. Create & Train the Risk Scoring Model (random forest classifier)\n",
    "6. Save and deploy the trained model in WML Engine (Watson Machine Learning)\n",
    "7. Configure AI OpenScale for Monitoring Model Quality (fairness & accuracy) and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-requisities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in a Watson Studio project, using with **Python 3.5 with Spark** runtime environment. **If you are viewing this in Watson Studio and do not see Python 3.5 with Spark in the upper right corner of your screen, please update the runtime now.** It requires service credentials for the following Cloud services:\n",
    "  * IBM Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "  \n",
    "If you have a paid Cloud account, you may also provision a **Databases for PostgreSQL** or **Db2 Warehouse** service to take full advantage of integration with Watson Studio and continuous learning services. If you choose not to provision this paid service, you can use the free internal PostgreSQL storage with OpenScale, but will not be able to configure continuous learning for your model.\n",
    "\n",
    "The notebook will train, create and deploy a German Credit Risk model, configure OpenScale to monitor that deployment, and inject seven days' worth of historical records and measurements for viewing in the OpenScale Insights dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Required packages installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INSTALL/UPGRADE \n",
    "!rm -rf $PIP_BUILD\n",
    "!pip install psycopg2-binary | tail -n 1\n",
    "!pip install --upgrade watson-machine-learning-client --no-cache | tail -n 1\n",
    "#!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n",
    "!pip install ibm_ai_openscale | tail -n 1\n",
    "!pip install --upgrade numpy --no-cache | tail -n 1\n",
    "!pip install --upgrade lime --no-cache | tail -n 1\n",
    "!pip install --upgrade SciPy --no-cache | tail -n 1\n",
    "!pip install 'pyspark==2.1.2' --force-reinstall  | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check installed packages and their versions, uncomment the line below\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configuring Credentials & Settings for provisioning services (MANDATORY TO CHECK!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/watson-openscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"COPY_YOUR_API_KEY_STRING_HERE_WITHIN_DOUBLE_QUOTES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will need credentials for Watson Machine Learning. If you already have a WML instance, you may use credentials for it. To provision a new Lite instance of WML, use the [Cloud catalog](https://cloud.ibm.com/catalog/services/machine-learning), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your WML credentials into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {COPY_YOUR_WML_SERVICE_CREDENTIALS_HERE_WITHIN_CURLY_BRACKETS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI OpenScale uses either a PostgreSQL or a Db2 database to store model deployment output and retraining data.  \n",
    "* In AIOS terms, this is called a 'datamart'\n",
    "* A free 'internal' database is available with AIOS for Lite plan users to get started.  \n",
    "* Alternatively, you can use your existing Db2 or PostgreSQL database, or purchase a new one.  \n",
    "\n",
    "This lab can use Databases for PostgreSQL, Db2 Warehouse, or a free internal version of PostgreSQL to create a datamart for OpenScale.\n",
    "\n",
    "If you have previously configured OpenScale, it will use your existing datamart, and not interfere with any models you are currently monitoring. Do not update the cell below.\n",
    "\n",
    "If you do not have a paid Cloud account or would prefer not to provision this paid service, you may use the free internal PostgreSQL service with OpenScale. Do not update the cell below.\n",
    "\n",
    "To provision a new instance of Db2 Warehouse, locate [Db2 Warehouse in the Cloud catalog](https://cloud.ibm.com/catalog/services/db2-warehouse), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Db2 Warehouse credentials into the cell below.\n",
    "\n",
    "To provision a new instance of Databases for PostgreSQL, locate [Databases for PostgreSQL in the Cloud catalog](https://cloud.ibm.com/catalog/services/databases-for-postgresql), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Databases for PostgreSQL credentials into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you do NOT have Db2, or do NOT want to use it with AIOS, set the DB_CREDENTIALS = None\n",
    "#DB_CREDENTIALS = None\n",
    "\n",
    "# If you DO have Db2, and do WANT to use it with AIOS, set the DB_CREDENTIALS = {<copy credentials json-string from Db2 service}\n",
    "DB_CREDENTIALS = {COPY_YOUR_DB_SERVICE_CREDENTIALS_HERE_WITHIN_CURLY_BRACKETS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you previously configured OpenScale to use the free internal version of PostgreSQL, you can switch to a new datamart using a paid database service.__ If you would like to delete the internal PostgreSQL configuration and create a new one using service credentials supplied in the cell above, set the __KEEP_MY_INTERNAL_POSTGRES__ variable below to __False__ below. In this case, the notebook will remove your existing internal PostgreSQL datamart and create a new one with the supplied credentials. __*NO DATA MIGRATION WILL OCCUR.*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you DID configure AIOS previously to use the internal 'Lite database', and want to use it, set KEEP_MY_INTERNAL_POSTGRES = True\n",
    "#KEEP_MY_INTERNAL_POSTGRES = True\n",
    "\n",
    "# If you did NOT configure AIOS previously with the internal 'Lite database', or do NOT want to use it, set KEEP_MY_INTERNAL_POSTGRES = False\n",
    "KEEP_MY_INTERNAL_POSTGRES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point you may either 1) Run the whole Notebook or 2) Proceed to run cells below step-by-step\n",
    "\n",
    "**After veriefied and set all the appropriate configuration settings above**, the notebook is ready to run.\n",
    "\n",
    "You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load and explore data for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm credit_risk_training.csv\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "df_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data (schema only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create & Train the Risk Scoring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to training and evaluation sets (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = df_data\n",
    "(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n",
    "\n",
    "MODEL_NAME = \"Spark German Risk Model - Final\"\n",
    "DEPLOYMENT_NAME = \"Spark German Risk Deployment - Final\"\n",
    "\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set target & features and create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "\n",
    "si_CheckingStatus = StringIndexer(inputCol = 'CheckingStatus', outputCol = 'CheckingStatus_IX')\n",
    "si_CreditHistory = StringIndexer(inputCol = 'CreditHistory', outputCol = 'CreditHistory_IX')\n",
    "si_LoanPurpose = StringIndexer(inputCol = 'LoanPurpose', outputCol = 'LoanPurpose_IX')\n",
    "si_ExistingSavings = StringIndexer(inputCol = 'ExistingSavings', outputCol = 'ExistingSavings_IX')\n",
    "si_EmploymentDuration = StringIndexer(inputCol = 'EmploymentDuration', outputCol = 'EmploymentDuration_IX')\n",
    "si_Sex = StringIndexer(inputCol = 'Sex', outputCol = 'Sex_IX')\n",
    "si_OthersOnLoan = StringIndexer(inputCol = 'OthersOnLoan', outputCol = 'OthersOnLoan_IX')\n",
    "si_OwnsProperty = StringIndexer(inputCol = 'OwnsProperty', outputCol = 'OwnsProperty_IX')\n",
    "si_InstallmentPlans = StringIndexer(inputCol = 'InstallmentPlans', outputCol = 'InstallmentPlans_IX')\n",
    "si_Housing = StringIndexer(inputCol = 'Housing', outputCol = 'Housing_IX')\n",
    "si_Job = StringIndexer(inputCol = 'Job', outputCol = 'Job_IX')\n",
    "si_Telephone = StringIndexer(inputCol = 'Telephone', outputCol = 'Telephone_IX')\n",
    "si_ForeignWorker = StringIndexer(inputCol = 'ForeignWorker', outputCol = 'ForeignWorker_IX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "si_Label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "va_features = VectorAssembler(inputCols=[\"CheckingStatus_IX\", \"CreditHistory_IX\", \"LoanPurpose_IX\", \"ExistingSavings_IX\", \"EmploymentDuration_IX\", \"Sex_IX\", \\\n",
    "                                         \"OthersOnLoan_IX\", \"OwnsProperty_IX\", \"InstallmentPlans_IX\", \"Housing_IX\", \"Job_IX\", \"Telephone_IX\", \"ForeignWorker_IX\", \\\n",
    "                                         \"LoanDuration\", \"LoanAmount\", \"InstallmentPercent\", \"CurrentResidenceDuration\", \"LoanDuration\", \"Age\", \"ExistingCreditsCount\", \\\n",
    "                                         \"Dependents\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREATING THE MODEL (RANDOM FOREST CLASSIFIER)\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[si_CheckingStatus, si_CreditHistory, si_EmploymentDuration, si_ExistingSavings, si_ForeignWorker, si_Housing, si_InstallmentPlans, si_Job, si_LoanPurpose, si_OthersOnLoan,\\\n",
    "                               si_OwnsProperty, si_Sex, si_Telephone, si_Label, va_features, classifier, label_converter])\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EVALUATE THE MODEL\n",
    "predictions = model.transform(test_data)\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "area_under_curve = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "#default evaluation method is areaUnderROC\n",
    "print(\"Area under ROC curve = %g\" % area_under_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save and deploy the trained model in WML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import json\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove existing model and deployment (if it exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SAVE THE MODEL IN WML\n",
    "model_deployment_ids = wml_client.deployments.get_uids()\n",
    "for deployment_id in model_deployment_ids:\n",
    "    deployment = wml_client.deployments.get_details(deployment_id)\n",
    "    model_id = deployment['entity']['deployable_asset']['guid']\n",
    "    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n",
    "        print('Deleting deployment id', deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print('Deleting model id', model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model properties and publish the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SET MODEL PROPERTIES IN WML\n",
    "model_props = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n",
    "        {\n",
    "           \"name\": \"areaUnderROC\",\n",
    "           \"value\": area_under_curve,\n",
    "           \"threshold\": 0.7\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET MODEL DETAILS FROM WML\n",
    "wml_models = wml_client.repository.get_details()\n",
    "model_uid = None\n",
    "for model_in in wml_models['models']['resources']:\n",
    "    if MODEL_NAME == model_in['entity']['name']:\n",
    "        model_uid = model_in['metadata']['guid']\n",
    "        break\n",
    "\n",
    "if model_uid is None:\n",
    "    print(\"Storing model ...\")\n",
    "\n",
    "    published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, training_data=train_data, pipeline=pipeline)\n",
    "    model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SHOW MODEL ID\n",
    "model_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model deployment in WML (to get a web service for scoring endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREATE MODEL DEPLOYMENT IN WML\n",
    "wml_deployments = wml_client.deployments.get_details()\n",
    "deployment_uid = None\n",
    "for deployment in wml_deployments['resources']:\n",
    "    if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "        deployment_uid = deployment['metadata']['guid']\n",
    "        break\n",
    "\n",
    "if deployment_uid is None:\n",
    "    print(\"Deploying model...\")\n",
    "\n",
    "    deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)\n",
    "    deployment_uid = wml_client.deployments.get_uid(deployment)\n",
    "    \n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Configure AI OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AI OpenScale instance GUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "AIOS_GUID = None\n",
    "token_data = {\n",
    "    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n",
    "    'response_type': 'cloud_iam',\n",
    "    'apikey': CLOUD_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\n",
    "iam_token = response.json()['access_token']\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "resources = json.loads(requests.get('https://resource-controller.cloud.ibm.com/v2/resource_instances', headers=iam_headers).text)['resources']\n",
    "for resource in resources:\n",
    "    if \"aiopenscale\" in resource['id'].lower():\n",
    "        AIOS_GUID = resource['guid']\n",
    "        \n",
    "AIOS_CREDENTIALS = {\n",
    "    \"instance_guid\": AIOS_GUID,\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "if AIOS_GUID is None:\n",
    "    print('AI OpenScale GUID NOT FOUND')\n",
    "else:\n",
    "    print(AIOS_GUID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the AIOS datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIOS datamart is used to store and maintain the results of AI Open Scale monitoring and fairness checks.\n",
    "#### IMPORTANT CHECK: Before proceeding, double check that you did set all your configuration options appropriately earlier in this Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ai_client = APIClient(aios_credentials=AIOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_mart_details = ai_client.data_mart.get_details()\n",
    "    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n",
    "        if KEEP_MY_INTERNAL_POSTGRES:\n",
    "            print('Using existing internal datamart.')\n",
    "        else:\n",
    "            if DB_CREDENTIALS is None:\n",
    "                print('No postgres credentials supplied. Using existing internal datamart')\n",
    "            else:\n",
    "                print('Switching to external datamart')\n",
    "                ai_client.data_mart.delete(force=True)\n",
    "                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "    else:\n",
    "        print('Using existing external datamart')\n",
    "except:\n",
    "    if DB_CREDENTIALS is None:\n",
    "        print('Setting up internal datamart')\n",
    "        ai_client.data_mart.setup(internal_db=True)\n",
    "    else:\n",
    "        print('Setting up external datamart')\n",
    "        try:\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "        except:\n",
    "            print('Setup failed, trying Db2 setup')\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_mart_details = ai_client.data_mart.get_details()\n",
    "data_mart_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind AIOS to your WML instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding means telling the AIOS which WML Engine is running the models to be validated.\n",
    "#### IMPORTANT CHECK: Before proceeding, double check that you did set all your configuration options appropriately earlier in this Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance(WML_CREDENTIALS))\n",
    "if binding_uid is None:\n",
    "    binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printout the WML binding_uid\n",
    "print(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List the deployed WML assets (models) that the AIOS can see\n",
    "ai_client.data_mart.bindings.list_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscribe AIOS to the 'German Risk Model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove existing credit risk subscriptions (if they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "for subscription in subscriptions_uids:\n",
    "    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n",
    "    if sub_name == MODEL_NAME:\n",
    "        ai_client.data_mart.subscriptions.delete(subscription)\n",
    "        print('Deleted existing subscription for', MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    model_uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    label_column='Risk',\n",
    "    prediction_column='predictedLabel',\n",
    "    probability_column='probability',\n",
    "    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n",
    "))\n",
    "\n",
    "if subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the current AIOS subscription list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subscription.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up AIOS Modeling Configuration for quality monitoring & feedback logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we'll need to score the 'German Risk Model' once to get a sample of the Data Schema, needed to configure Monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "credit_risk_scoring_endpoint = None\n",
    "print(deployment_uid)\n",
    "\n",
    "for deployment in wml_client.deployments.get_details()['resources']:\n",
    "    if deployment_uid in deployment['metadata']['guid']:\n",
    "        credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "        \n",
    "print(credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, payload_scoring)\n",
    "\n",
    "print(scoring_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling Quality Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the previous sample scoring, you'll need to wait at least ten seconds to allow the payload logging table to be set up, before we begin enabling monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.quality_monitoring.enable(threshold=0.7, min_records=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing additional Feedback Data and setup feedback logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** **To enable monitoring for *accuracy*, you must provide AIOS with *feedback data*.** Feedback data is manually labeled 'accurate' validation data, used by AIOS for model quality monitoring (to run model quality scoring tests). Accuracy information will not appear in the AIOS dashboard until feedback data is provided. You may submit additional feedback data to AIOS from your scoring applications or processes directly (code snippets are provided in AIOS), or you may load a collected sample feedback data at once (via REST API).\n",
    "\n",
    "For this task, this Notebook will download a CSV file that contains sample feedback data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm additional_feedback_data.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/additional_feedback_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('additional_feedback_data.json') as feedback_file:\n",
    "    additional_feedback_data = json.load(feedback_file)\n",
    "subscription.feedback_logging.store(additional_feedback_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.feedback_logging.show_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make AIOS to perform quality monitoring runs to measure quality and performance of the model\n",
    "run_details = subscription.quality_monitoring.run()\n",
    "status = run_details['status']\n",
    "id = run_details['id']\n",
    "print(id)\n",
    "\n",
    "print(\"Run status: {}\".format(status))\n",
    "\n",
    "start_time = time.time()\n",
    "elapsed_time = 0\n",
    "\n",
    "while status != 'completed' and elapsed_time < 60:\n",
    "    time.sleep(10)\n",
    "    run_details = subscription.quality_monitoring.get_run_details(run_uid=id)\n",
    "    status = run_details['status']\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Run status: {}\".format(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.get_run_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show quality monitoring run results\n",
    "subscription.quality_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Submit quality monitoring run results to AIOSS for feedback logging\n",
    "subscription.quality_monitoring._get_data_from_rest_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get quality & performance metrics from AIOS\n",
    "ai_client.data_mart.get_deployment_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling Fairness Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.fairness_monitoring.enable(\n",
    "            features=[\n",
    "                Feature(\"Sex\", majority=['male'], minority=['female'], threshold=0.95),\n",
    "                Feature(\"Age\", majority=[[26,75]], minority=[[18,25]], threshold=0.95)\n",
    "            ],\n",
    "            favourable_classes=['No Risk'],\n",
    "            unfavourable_classes=['Risk'],\n",
    "            min_records=1000,\n",
    "            training_data=pd_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the model again now that monitoring is configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load more sample records to score the model with\n",
    "!rm german_credit_feed.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_feed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score with 1000 randomly chosen records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(1000):\n",
    "    values.append(random.choice(scoring_data['values']))\n",
    "payload_scoring = {\"fields\": fields, \"values\": values}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, payload_scoring)\n",
    "print(scoring_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For demo purposes, we'll add 7 days of historical payloads and results to AIOS datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert historical payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show past fairness, we'll provide some more scoring records form history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm payload_history*.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_1.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_2.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_3.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_4.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_5.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_6.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/payload_history_7.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We'll use only last 7 days of record\n",
    "historyDays = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Loading day {}'.format(day + 1))\n",
    "    history_file = 'payload_history_' + str(day + 1) + '.json'\n",
    "    with open(history_file) as f:\n",
    "        payloads = json.load(f)\n",
    "        hourly_records = int(len(payloads) / 24)\n",
    "        index = 0\n",
    "        for hour in range(24):\n",
    "            recordsList = []\n",
    "            for i in range(hourly_records):\n",
    "                score_time = str(datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1))))\n",
    "                recordsList.append(PayloadRecord(request=payloads[index]['request'], response=payloads[index]['response'], scoring_timestamp=score_time))\n",
    "                index += 1\n",
    "            subscription.payload_logging.store(records=recordsList)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_mart_id = subscription.get_details()['metadata']['url'].split('/service_bindings')[0].split('marts/')[1]\n",
    "print(data_mart_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance_metrics_url = 'https://api.aiopenscale.cloud.ibm.com' + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/metrics'\n",
    "print(performance_metrics_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert historical fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm fairness_history.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/german-credit/master/fairness_history.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "token_data = {\n",
    "    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n",
    "    'response_type': 'cloud_iam',\n",
    "    'apikey': AIOS_CREDENTIALS['apikey']\n",
    "}\n",
    "\n",
    "response = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\n",
    "iam_token = response.json()['access_token']\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "with open('fairness_history.json', 'r') as history_file:\n",
    "    payloads = json.load(history_file)\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        \n",
    "        qualityMetric = {\n",
    "            'metric_type': 'fairness',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': random.choice(payloads)\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert historical quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_data = {\n",
    "    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n",
    "    'response_type': 'cloud_iam',\n",
    "    'apikey': AIOS_CREDENTIALS['apikey']\n",
    "}\n",
    "\n",
    "response = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\n",
    "iam_token = response.json()['access_token']\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "measurements = [0.76, 0.78, 0.68, 0.72, 0.73, 0.77, 0.80]\n",
    "for day in range(historyDays):\n",
    "    print('Day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        \n",
    "        qualityMetric = {\n",
    "            'metric_type': 'quality',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': {\n",
    "                'quality': measurements[day],\n",
    "                'threshold': 0.7,\n",
    "                'metrics': [\n",
    "                    {\n",
    "                        'name': 'auroc',\n",
    "                        'value': measurements[day],\n",
    "                        'threshold': 0.7\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert historical performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = {\n",
    "    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n",
    "    'response_type': 'cloud_iam',\n",
    "    'apikey': AIOS_CREDENTIALS['apikey']\n",
    "}\n",
    "\n",
    "response = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\n",
    "iam_token = response.json()['access_token']\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        score_count = random.randint(60, 600)\n",
    "        score_resp = random.uniform(60, 300)\n",
    "\n",
    "        performanceMetric = {\n",
    "            'metric_type': 'performance',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': {\n",
    "                'response_time': score_resp,\n",
    "                'records': score_count\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[performanceMetric], headers=iam_headers)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import *\n",
    "subscription.explainability.enable(training_data=pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.explainability.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fairness monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kick off a fairness monitor run on current data. Depending on how fast the monitor runs, the table may not contain the most recent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_details = subscription.fairness_monitoring.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription.fairness_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data to help debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Datamart:', data_mart_id)\n",
    "print('Model:', model_uid)\n",
    "print('Deployment:', deployment_uid)\n",
    "print('Binding:', binding_uid)\n",
    "print('Scoring URL:', credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify transactions for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transaction IDs** (\"scoring_id) identified by the cells below can be copied and pasted into the Explainability tab of the OpenScale dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_data = subscription.payload_logging.get_table_content(limit=60)\n",
    "payload_data.filter(items=['scoring_id', 'predictedLabel', 'probability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have finished the hands-on lab for IBM Watson OpenScale. You can now view the [OpenScale Dashboard](https://aiopenscale.cloud.ibm.com/).\n",
    "\n",
    "Click on the tile for the German Credit model to see fairness, accuracy, and performance monitors.\n",
    "\n",
    "Click on the timeseries graph to get detailed information on transactions during a specific time window.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "OpenScale shows model performance over time. You have two options to keep data flowing to your OpenScale graphs:\n",
    "  * Download, configure and schedule the [model feed notebook](https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_scoring_feed.ipynb). This notebook can be set up with your WML credentials, and scheduled to provide a consistent flow of scoring requests to your model, which will appear in your OpenScale monitors.\n",
    "  * Re-run this notebook. Running this notebook from the beginning will delete and re-create the model and deployment, and re-create the historical data. Please note that the payload and measurement logs for the previous deployment will continue to be stored in your datamart, and cal be deleted if necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
